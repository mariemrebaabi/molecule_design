{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qfioK_RjlLV",
        "outputId": "87733049-f95b-4d66-e971-a7bd8da9ade2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.10/dist-packages (2022.9.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.22.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (8.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GCVAE\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem.Crippen import MolLogP, MolMR\n",
        "\n",
        "def graph_features(mol, atom_labels, max_length=None):\n",
        "    max_length = max_length if max_length is not None else mol.GetNumAtoms()\n",
        "    features = np.array([[*[a.GetAtomicNum() == i for i in atom_labels]] for a in mol.GetAtoms()], dtype=np.int32)\n",
        "    return np.vstack((features, np.zeros((max_length - features.shape[0], features.shape[1]))))\n",
        "\n",
        "def feature_size(mol, atom_labels, max_length=None): \n",
        "    feature = graph_features(mol, atom_labels, max_length)\n",
        "    feature = torch.cat([torch.tensor(feature), torch.zeros([max_length-feature.shape[0], feature.shape[1]])], 0)\n",
        "    for i in range(feature.shape[0]):\n",
        "        if 1 not in feature[i]:\n",
        "            feature[i, 0] = 1\n",
        "    return feature\n",
        "\n",
        "def graph_adjacency(mol, atom_number, bond_encoder_m, connected=True):\n",
        "    A = np.zeros(shape=(atom_number, atom_number), dtype=np.int32)\n",
        "    begin, end = [b.GetBeginAtomIdx() for b in mol.GetBonds()], [b.GetEndAtomIdx() for b in mol.GetBonds()]\n",
        "    bond_type = [bond_encoder_m[b.GetBondType()] for b in mol.GetBonds()]\n",
        "    A[begin, end] = bond_type\n",
        "    A[end, begin] = bond_type\n",
        "    degree = np.sum(A[:mol.GetNumAtoms(), :mol.GetNumAtoms()], axis=-1)\n",
        "    adj = A if connected and (degree > 0).all() else None\n",
        "    for i in range(adj.shape[0]):\n",
        "        adj[i, 0:i] = 0\n",
        "    oh_list = []\n",
        "    for i in range(adj.shape[0]):\n",
        "        oh = np.zeros(shape=(atom_number, 5), dtype=np.int32)\n",
        "        for j in range(adj.shape[1]):\n",
        "            oh[j, adj[i][j]] = 1\n",
        "        oh_list.append(torch.tensor(oh))\n",
        "    return torch.cat([o for o in oh_list], 1)\n",
        "\n",
        "def graph2mol(node_labels, adjacency, atom_decoder_m, bond_decoder_m, strict=False):\n",
        "    mol = Chem.RWMol()\n",
        "    for node_label in node_labels:\n",
        "        mol.AddAtom(Chem.Atom(atom_decoder_m[node_label]))\n",
        "    for start, end in zip(*np.nonzero(adjacency)):\n",
        "        if start < end:\n",
        "            mol.AddBond(int(start), int(end), bond_decoder_m[adjacency[start, end]])\n",
        "    if strict:\n",
        "        try:\n",
        "            Chem.SanitizeMol(mol)\n",
        "        except:\n",
        "            mol = None\n",
        "    return mol\n",
        "\n",
        "def results(cvae, condition_1, condition_2, generate, z_dim, cond_dim, \n",
        "            size, atom_labels, row_dim, col_dim, atom_decoder_m, bond_decoder_m):\n",
        "    with torch.no_grad():\n",
        "        z = torch.randn(int(generate), z_dim).cuda()\n",
        "        c1 = torch.zeros(int(generate), cond_dim).cuda()\n",
        "        c1[:,condition_1] = 1\n",
        "        c2 = torch.zeros(int(generate), cond_dim).cuda()\n",
        "        c2[:,condition_2] = 1\n",
        "        sample = cvae.decoder(z, c1, c2)\n",
        "    smi = []\n",
        "    logp = []\n",
        "    mr = []\n",
        "    for test_sample in sample.view(int(generate), 1, row_dim, col_dim).cpu():\n",
        "        try:\n",
        "            atom_num = test_sample[0][:, 0:1].max(dim=0).indices[0].item()+1\n",
        "            if atom_num < size:\n",
        "                test_sample = test_sample[0][:atom_num, :]\n",
        "            else:\n",
        "                test_sample = test_sample[0]\n",
        "            atom_mat = test_sample[:, 1:len(atom_labels)+1]\n",
        "            nodes_hard_max = torch.max(atom_mat, -1)[1]\n",
        "            bond_mat = test_sample[:, len(atom_labels)+1:len(atom_labels)+1+5*atom_num]\n",
        "            bond_mat = torch.tensor(np.array(bond_mat))\n",
        "            bond_mats = []\n",
        "            for i in range(0, bond_mat.shape[1], 5):\n",
        "                B = np.zeros(shape=(atom_num, 5), dtype=np.int32)\n",
        "                if i+6 > bond_mat.shape[1]:\n",
        "                    bm = bond_mat[:,i:]\n",
        "                    for n in range(bm.shape[0]):\n",
        "                        b = bm[n]\n",
        "                        B[n, torch.max(b, -1)[1]] = 1\n",
        "                    bond_mats.append(B)\n",
        "                else:\n",
        "                    bm = bond_mat[:,i:i+5]\n",
        "                    for n in range(bm.shape[0]):\n",
        "                        b = bm[n]\n",
        "                        B[n, torch.max(b, -1)[1]] = 1\n",
        "                    bond_mats.append(B)\n",
        "            edges_hard = torch.tensor(bond_mats)\n",
        "            edges_hard_max = torch.max(edges_hard, -1)[1]\n",
        "            mol = graph2mol(nodes_hard_max.numpy(), edges_hard_max.numpy(), \n",
        "                            atom_decoder_m, bond_decoder_m, strict=True)\n",
        "            try:\n",
        "                if '.' not in Chem.MolToSmiles(mol):\n",
        "                    smi.append(Chem.MolToSmiles(mol))\n",
        "                    logp.append(MolLogP(mol))\n",
        "                    mr.append(MolMR(mol))\n",
        "            except:\n",
        "                continue\n",
        "        except:\n",
        "            continue\n",
        "    cvae_df = pd.DataFrame({'SMILES':smi, 'C1':logp, 'C2':mr})\n",
        "    return cvae_df"
      ],
      "metadata": {
        "id": "YLZ_waTuPzhi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem.Crippen import MolLogP, MolMR\n",
        "from rdkit import RDLogger\n",
        "RDLogger.DisableLog('rdApp.*')\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "import argparse\n",
        "\n",
        "#from graph_converter import graph_features, feature_size, graph_adjacency, graph2mol, results\n",
        "\n",
        "parser = argparse.ArgumentParser(description='Small Molecular Graph Conditional Variational Autoencoder for Multi-objective Optimization (logP & Molar Refractivity)')\n",
        "parser.add_argument('-f')\n",
        "parser.add_argument('--data', type=int, default=80000, help='Sampling (default=80000)')\n",
        "parser.add_argument('--size', type=int, default=10, help='molecule size (default=10)')\n",
        "parser.add_argument('--dataset', type=str, default='/content/smile+proprties (1).csv', help=\"dataset path (default='../data/ZINC_logP_MR.csv')\")\n",
        "#parser.add_argument('--conditions', type=str, default='/content/conditions.csv', help=\"conditions path (default='../data/conditions.csv')\")\n",
        "parser.add_argument('--batch', type=int, default=100, help='batch size (default=100)')\n",
        "parser.add_argument('--epochs', type=int, default=1000, help='epoch (default=1000)')\n",
        "parser.add_argument('--test', type=float, default=0.1, help='test set ratio (default=0.1)')\n",
        "parser.add_argument('--lr', type=float, default=0.00005, help='learning rate (default=0.00005)')\n",
        "parser.add_argument('--gen', type=int, default=10000, help='number of molecules to be generated (default=10000)')\n",
        "parser.add_argument('--output', type=str, default='/content/results', help=\"output files path (default='../results/generated')\")\n",
        "args = parser.parse_args()\n",
        "\n",
        "print()\n",
        "print(f'- Sampling: {args.data}')\n",
        "print(f'- Molecule size: {args.size}')\n",
        "print(f'- Dataset: {args.dataset}')\n",
        "#print(f'- Conditions: {args.conditions}')\n",
        "print(f'- Batch size: {args.batch}')\n",
        "print(f'- Epoch: {args.epochs}')\n",
        "print(f'- Test set ratio: {args.test}')\n",
        "print(f'- Learning rate: {args.lr}')\n",
        "print(f'- Generated molecules: {args.gen}')\n",
        "print(f'- Output path: {args.output}')\n",
        "print()\n",
        "\n",
        "\n",
        "class CVAE(nn.Module):\n",
        "    def __init__(self, x_dim, h_dim1, h_dim2, z_dim, c_dim):\n",
        "        super(CVAE, self).__init__()\n",
        "        # encoder part\n",
        "        self.fc1 = nn.Linear(x_dim+c_dim*2, h_dim1)\n",
        "        self.fc2 = nn.Linear(h_dim1, h_dim2)\n",
        "        self.fc31 = nn.Linear(h_dim2, z_dim)\n",
        "        self.fc32 = nn.Linear(h_dim2, z_dim)\n",
        "        # decoder part\n",
        "        self.fc4 = nn.Linear(c_dim*2+z_dim, h_dim2)\n",
        "        self.fc5 = nn.Linear(h_dim2, h_dim1)\n",
        "        self.fc6 = nn.Linear(h_dim1, x_dim)\n",
        "    \n",
        "    def encoder(self, x, c1, c2):\n",
        "        concat_input = torch.cat([x, c1, c2], 1)\n",
        "        h = F.relu(self.fc1(concat_input))\n",
        "        h = F.relu(self.fc2(h))\n",
        "        return self.fc31(h), self.fc32(h)\n",
        "    \n",
        "    def sampling(self, mu, log_var):\n",
        "        std = torch.exp(0.5*log_var)\n",
        "        eps = torch.randn_like(std)\n",
        "        return eps.mul(std).add(mu)\n",
        "    \n",
        "    def decoder(self, z, c1, c2):\n",
        "        concat_input = torch.cat([z, c1, c2], 1)\n",
        "        h = F.relu(self.fc4(concat_input))\n",
        "        h = F.relu(self.fc5(h))\n",
        "        return torch.sigmoid(self.fc6(h))\n",
        "    \n",
        "    def forward(self, x, c1, c2):\n",
        "        mu, log_var = self.encoder(x.view(-1, out_dim), c1, c2)\n",
        "        z = self.sampling(mu, log_var)\n",
        "        return self.decoder(z, c1, c2), mu, log_var\n",
        "\n",
        "def loss_function(recon_x, x, mu, log_var):\n",
        "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, out_dim), reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
        "    return BCE + KLD\n",
        "\n",
        "def one_hot(labels, class_size): \n",
        "    targets = torch.zeros(labels.shape[0], class_size)\n",
        "    for i, label in enumerate(labels):\n",
        "        targets[i, round(label.item())] = 1\n",
        "    return Variable(targets)\n",
        "\n",
        "def train(epoch):\n",
        "    cvae.train()\n",
        "    train_loss = 0\n",
        "    for batch_idx, (graph, logp, mr) in enumerate(train_loader):\n",
        "        graph = graph.cuda()\n",
        "        logp = one_hot(logp, cond_dim).cuda()\n",
        "        mr = one_hot(mr, cond_dim).cuda()\n",
        "        optimizer.zero_grad()\n",
        "        recon_batch, mu, log_var = cvae(graph, logp, mr)\n",
        "        loss = loss_function(recon_batch, graph, mu, log_var)\n",
        "        loss.backward()\n",
        "        \n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "    print('> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader.dataset)))\n",
        "    return train_loss / len(train_loader.dataset)\n",
        "\n",
        "def test():\n",
        "    cvae.eval()\n",
        "    test_loss= 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (graph, logp, mr) in enumerate(test_loader):\n",
        "            graph = graph.cuda()\n",
        "            logp = one_hot(logp, cond_dim).cuda()\n",
        "            mr = one_hot(mr, cond_dim).cuda()\n",
        "            recon, mu, log_var = cvae(graph, logp, mr)\n",
        "            test_loss += loss_function(recon, graph, mu, log_var).item()\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('> Test set loss: {:.4f}'.format(test_loss))\n",
        "    return test_loss\n",
        "\n",
        "\n",
        "\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKpiJMsAiOtU",
        "outputId": "207a94a8-46bb-46d3-938a-402dba1ff7ee"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "- Sampling: 80000\n",
            "- Molecule size: 10\n",
            "- Dataset: /content/smile+proprties (1).csv\n",
            "- Batch size: 100\n",
            "- Epoch: 1000\n",
            "- Test set ratio: 0.1\n",
            "- Learning rate: 5e-05\n",
            "- Generated molecules: 10000\n",
            "- Output path: /content/results\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(args.dataset)\n",
        "df = df[df['Length'] <= args.size].reset_index(drop=True)\n",
        "print('- Total data:', df.shape[0])\n",
        "try:\n",
        "    df = df.sample(n=args.data).reset_index(drop=True)\n",
        "    print('- Sampled data:', df.shape[0])\n",
        "except:\n",
        "    print(f'Sampling error: Set the value of --data lower than {df.shape[0]}.')\n",
        "    quit()\n",
        "print()\n",
        "\n",
        "smiles = df['SMILES'].tolist()\n",
        "data = [Chem.MolFromSmiles(line) for line in smiles]\n",
        "\n",
        "# Change it for customizing.\n",
        "logp = df['logP'].tolist()\n",
        "mr = [round(v/10) for v in df['MR']]\n",
        "\n",
        "atom_labels = sorted(set([atom.GetAtomicNum() for mol in data for atom in mol.GetAtoms()] + [0]))\n",
        "atom_encoder_m = {l: i for i, l in enumerate(atom_labels)}\n",
        "atom_decoder_m = {i: l for i, l in enumerate(atom_labels)}\n",
        "\n",
        "bond_labels = [Chem.rdchem.BondType.ZERO] + list(sorted(set(bond.GetBondType() for mol in data for bond in mol.GetBonds())))\n",
        "bond_encoder_m = {l: i for i, l in enumerate(bond_labels)}\n",
        "bond_decoder_m = {i: l for i, l in enumerate(bond_labels)}\n",
        "\n",
        "\n",
        "print('Converting to graphs...')\n",
        "data_list = []\n",
        "logp_list = []\n",
        "mr_list = []\n",
        "atom_number = args.size\n",
        "for i in range(len(data)):\n",
        "#     try:\n",
        "    length = [[0] for i in range(args.size)]\n",
        "    length[int(df['Length'].iloc[i])-1] = [1]\n",
        "    length = torch.tensor(length)\n",
        "    data_list.append(torch.cat([length,feature_size(data[i], atom_labels, atom_number), \n",
        "                                graph_adjacency(data[i], atom_number, bond_encoder_m)], 1).float())\n",
        "    logp_list.append(logp[i])\n",
        "    mr_list.append(mr[i])\n",
        "#     except:\n",
        "#         print('Error:', df['SMILES'].iloc[i])\n",
        "#         continue\n",
        "\n",
        "train_list = []\n",
        "for i in range(len(data_list)):\n",
        "    train_list.append([np.array([np.array(data_list[i])]), np.array(logp_list[i]), np.array(mr_list[i])])\n",
        "\n",
        "bs = args.batch\n",
        "tr = 1-args.test\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_list[:int(len(train_list)*tr)], batch_size=bs, shuffle=True, drop_last=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=train_list[int(len(train_list)*tr):], batch_size=bs, shuffle=True, drop_last=True)\n",
        "\n",
        "print()\n",
        "print('- Train set:', len(train_list[:int(len(train_list)*tr)]))\n",
        "print('- Test set:', len(train_list[int(len(train_list)*tr):]))\n",
        "print()\n",
        "\n",
        "row_dim = train_list[0][0][0].shape[0]\n",
        "col_dim = train_list[0][0][0].shape[1]\n",
        "cond_dim = args.size\n",
        "out_dim = row_dim*col_dim\n",
        "z_dim = 128\n",
        "cvae = CVAE(x_dim=out_dim, h_dim1=512, h_dim2=256, z_dim=z_dim, c_dim=cond_dim)\n",
        "if torch.cuda.is_available():\n",
        "    cvae.cuda()\n",
        "\n",
        "optimizer = optim.Adam(cvae.parameters(), lr=args.lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-2PzWV91MM4",
        "outputId": "add67fa5-5149-4d33-e51f-9cb26bd2440f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Total data: 14438\n",
            "Sampling error: Set the value of --data lower than 14438.\n",
            "\n",
            "Converting to graphs...\n",
            "\n",
            "- Train set: 12994\n",
            "- Test set: 1444\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CVAE(\n",
              "  (fc1): Linear(in_features=660, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (fc31): Linear(in_features=256, out_features=128, bias=True)\n",
              "  (fc32): Linear(in_features=256, out_features=128, bias=True)\n",
              "  (fc4): Linear(in_features=148, out_features=256, bias=True)\n",
              "  (fc5): Linear(in_features=256, out_features=512, bias=True)\n",
              "  (fc6): Linear(in_features=512, out_features=640, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved weights\n",
        "cvae.load_state_dict(torch.load('/content/cvae_weights.h5'))\n",
        "cvae.eval()\n",
        "# Evaluate the model on a test dataset\n",
        "with torch.no_grad():\n",
        "    test_loss = test()\n",
        "    print(f'Test Loss: {test_loss:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "A-Sh53FGv_LN",
        "outputId": "3234a7c9-aedf-4549-a4e2-aa460b1ec15c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6449a575011b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the saved weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/cvae_weights.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Evaluate the model on a test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cvae' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#already save the weights\n",
        "\n",
        "print('Training the model...')\n",
        "train_loss_list = []\n",
        "test_loss_list = []\n",
        "for epoch in range(1, args.epochs+1):\n",
        "    train_loss = train(epoch)\n",
        "    train_loss_list.append(train_loss)\n",
        "    test_loss = test()\n",
        "    test_loss_list.append(test_loss)\n",
        "# After training\n",
        "torch.save(cvae.state_dict(), 'cvae_weights.h5')\n",
        "\n",
        "print()\n",
        "print('Generating molecules...')\n",
        "#conditions = pd.read_csv(args.conditions)\n",
        "#cond_1 = conditions['Cond_1'].tolist()\n",
        "#cond_2 = conditions['Cond_2'].tolist()\n",
        "c1 = int(input(\"Enter value for condition_1: \"))\n",
        "c2 = int(input(\"Enter value for condition_2: \"))\n",
        "#for c1, c2 in zip(cond_1, cond_2):\n",
        "cvae_df = results(cvae, c1, c2, args.gen, z_dim, cond_dim,  atom_number, atom_labels, row_dim, col_dim, atom_decoder_m, bond_decoder_m)\n",
        "cvae_df.to_csv(f'{args.output}_{c1}_{c2}.csv', index=False)\n",
        "print(f'Saving {args.output}_{c1}_{c2}.csv ({cvae_df.shape[0]})...')\n",
        "\n",
        "print()\n",
        "print('Done!')"
      ],
      "metadata": {
        "id": "9JZmzxxD0q-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M2f5EICRpBdn"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}